{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame, Panel\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import log_loss\n",
    "import datetime\n",
    "from random import random\n",
    "from collections import defaultdict\n",
    "from numpy import isnan\n",
    "import numpy\n",
    "import operator\n",
    "from scipy import spatial\n",
    "from operator import truediv\n",
    "from pylab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 861,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random as rand\n",
    "rand.randrange(1,5,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glogal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impression = pd.read_pickle('../data/processed/joined_impressions.pkl').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "impression['date'] = impression['impressionTimestamp'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "articles = pd.read_pickle('../data/processed/articles.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "satisfiedlist = []\n",
    "for i in list(impression.maxDuration):\n",
    "    if i >= 10000:\n",
    "        satisfiedlist.append(1)\n",
    "    else:\n",
    "        satisfiedlist.append(0)\n",
    "\n",
    "impression['satisfiedlist'] = satisfiedlist        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "category_flatten = [val for sublist in articles.categories.values for val in sublist]\n",
    "\n",
    "category_flatten = list(set(category_flatten))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rich_impression = impression.merge(articles, left_on=\"contentId\",right_on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from itertools import chain\n",
    "\n",
    "def columns_to_key_feature_pairs(row, key_column, feature_columns):\n",
    "    return [(row[key_column], '{}={}'.format(column, row[column])) for column in feature_columns]\n",
    "\n",
    "def array_column_to_key_feature_pairs(row, key_column, array_column):\n",
    "    return [(row[key_column], u'{}={}'.format(array_column, value)) for value in row[array_column]]\n",
    "\n",
    "feature_columns = ['id', 'hotness', 'lifetime']\n",
    "\n",
    "item_features = pd.DataFrame.from_records(\n",
    "    data=chain.from_iterable(\n",
    "        columns_to_key_feature_pairs(row, key_column='id', feature_columns=feature_columns) +\\\n",
    "        array_column_to_key_feature_pairs(row, key_column='id', array_column='categories') +\\\n",
    "        array_column_to_key_feature_pairs(row, key_column='id', array_column='tags')\n",
    "        for _, row in articles.iterrows()), \n",
    "    columns=['item', 'feature_name'],\n",
    "    index='item')\n",
    "\n",
    "#item_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_position = impression.contentPosition.max()\n",
    "content_positions = np.arange(max_position+1)\n",
    "\n",
    "context_features = pd.DataFrame.from_dict(\n",
    "    {'contentPosition': content_positions, 'feature_name': ['position={}'.format(p) for p in content_positions]}\n",
    ").set_index('contentPosition')\n",
    "\n",
    "#context_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_features = pd.concat([item_features, context_features],axis=0)\n",
    "\n",
    "all_features.feature_name = all_features.feature_name.astype('category')\n",
    "all_features['encoded_feature'] = all_features.feature_name.cat.codes\n",
    "\n",
    "#all_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### user with category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "environmentlist = list(set(rich_impression[\"environmentId\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grouped = rich_impression.groupby([\"environmentId\"])\n",
    "dic = {}\n",
    "for item in environmentlist:\n",
    "    l = grouped.get_group(item)[\"categories\"].tolist()\n",
    "    flatten =  list(set([item for sublist in l for item in sublist]))\n",
    "    dic[item] = flatten\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "userinfor = pd.DataFrame({\"environmentid\": list(dic.keys()),\"category\": list(dic.values())})\n",
    "\n",
    "flat_userinfor = pd.DataFrame(\n",
    "    data=[(index, category)\n",
    "         for index, row in userinfor.iterrows()\n",
    "         for category in row.category],\n",
    "    columns=['index', 'category']).set_index(\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### we cluster different users into 20 groups based on interests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder \n",
    "\n",
    "from scipy import sparse\n",
    "\n",
    "import scipy.sparse as sp\n",
    "\n",
    "def feature_matrix(rich_impressions, column_name):\n",
    "    \n",
    "    category_encoder = LabelEncoder()\n",
    "\n",
    "    rich_impressions = rich_impressions.assign(encoded_column=lambda df: category_encoder.fit_transform(df[column_name]))\n",
    "\n",
    "    row_indexes = rich_impressions.index.values    \n",
    "    column_indexes = rich_impressions.encoded_column.values\n",
    "    \n",
    "    output = sparse.coo_matrix(\n",
    "        (np.ones_like(column_indexes), \n",
    "        (row_indexes, column_indexes)))    \n",
    "    \n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def singletag(mergedate, name):\n",
    "    \n",
    "    enc = OneHotEncoder()\n",
    "\n",
    "    X = enc.fit_transform(mergedate[[name]].values)\n",
    "    \n",
    "    #result = X.toarray()\n",
    "    \n",
    "    return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.cluster import KMeans  \n",
    "\n",
    "def kmeans(X, n_clusters):\n",
    "\n",
    "    labeler = KMeans(n_clusters) \n",
    "\n",
    "    labeler.fit(X.tocsr())  \n",
    "    \n",
    "    return labeler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def indices( mylist, value):\n",
    "    return [i for i,x in enumerate(mylist) if x==value]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_user = feature_matrix(flat_userinfor, \"category\")\n",
    "\n",
    "labeler = kmeans(X_user,20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select just one groups to do the experient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index_6 = indices(labeler.labels_, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find rich_impression  data set for each group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grouped_rich_impression(indexlist, userinfor, rich_impression):\n",
    "    idx = userinfor.index.isin(indexlist)\n",
    "    groupeduserinf = userinfor[idx]\n",
    "    groupedenvironment = groupeduserinf.environmentid.values.tolist()\n",
    "    im_idx = rich_impression.environmentId.isin(groupedenvironment)\n",
    "    group_rich_impression = rich_impression[im_idx]\n",
    "    return groupeduserinf,group_rich_impression\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "groupeduserinf,grouped_rich_impression = grouped_rich_impression(index_6, userinfor, rich_impression)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### There are seven days, we can seen as seven frontpages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CTRforday(grouped_rich_impression):\n",
    "\n",
    "    up = grouped_rich_impression.groupby([\"date\"]).aggregate({\"isClicked\":sum})\n",
    "    \n",
    "    down = grouped_rich_impression.groupby([\"date\"]).aggregate({\"isClicked\":len})\n",
    "    \n",
    "    CTR = up.isClicked.values/down.isClicked.values\n",
    "    \n",
    "    up[\"CTR\"] = CTR\n",
    "    \n",
    "    result = up.sort(columns=\"CTR\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/XiHUANG/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:11: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isClicked</th>\n",
       "      <th>CTR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-06-18</th>\n",
       "      <td>399.0</td>\n",
       "      <td>0.020440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-19</th>\n",
       "      <td>162.0</td>\n",
       "      <td>0.023028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-14</th>\n",
       "      <td>99.0</td>\n",
       "      <td>0.030165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-15</th>\n",
       "      <td>66.0</td>\n",
       "      <td>0.033183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-16</th>\n",
       "      <td>64.0</td>\n",
       "      <td>0.035301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-13</th>\n",
       "      <td>86.0</td>\n",
       "      <td>0.036013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-06-17</th>\n",
       "      <td>104.0</td>\n",
       "      <td>0.044199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            isClicked       CTR\n",
       "date                           \n",
       "2017-06-18      399.0  0.020440\n",
       "2017-06-19      162.0  0.023028\n",
       "2017-06-14       99.0  0.030165\n",
       "2017-06-15       66.0  0.033183\n",
       "2017-06-16       64.0  0.035301\n",
       "2017-06-13       86.0  0.036013\n",
       "2017-06-17      104.0  0.044199"
      ]
     },
     "execution_count": 750,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = CTRforday(grouped_rich_impression) \n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### seperate the dataset, train is  based on (2017-06-13 ~ 2017-06-18), test is based on (2017-06-19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def selecttraintest(impression,n):\n",
    "        impression[\"index\"] = pd.to_datetime(impression.date)\n",
    "\n",
    "        temp =  impression.set_index(\"index\") \n",
    "        if n==0:\n",
    "            print(n)\n",
    "\n",
    "            data = temp['2017-06-13':'2017-06-18']\n",
    "        if n==1:\n",
    "            data = temp['2017-06-19']\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/XiHUANG/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "train_data_total = selecttraintest(grouped_rich_impression,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/XiHUANG/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "test_data_total = selecttraintest(grouped_rich_impression,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-arrange articles from just one day(2017-06-19), obtain related context vector, this data set as the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contextvectorfun(grouped_rich_impression, n ):\n",
    "    \n",
    "    \n",
    "    traincandidate = pd.DataFrame()\n",
    "    shrinkdate_impression = grouped_rich_impression\n",
    "    shrinkdate_impression = shrinkdate_impression.reset_index()\n",
    "    flat_date_impression = pd.DataFrame(\n",
    "    data=[(index, tags)\n",
    "         for index, row in shrinkdate_impression.iterrows()\n",
    "         for tags in row.tags],\n",
    "    columns=['index', 'tags']).set_index(\"index\")\n",
    "    \n",
    "    contextvector = feature_matrix(flat_date_impression, 'tags')\n",
    "    \n",
    "    try1 = []\n",
    "    for item in contextvector.toarray():\n",
    "        try1.append(item)\n",
    "        \n",
    "    shrinkdate_impression[\"contextvector\"] = try1\n",
    "    \n",
    "    #del shrinkdate_impression[\"index\"]\n",
    "    \n",
    "    shrinkdate_impression[\"index\"] = pd.to_datetime(shrinkdate_impression.date)\n",
    "\n",
    "    temp =  shrinkdate_impression.set_index(\"index\") \n",
    "    if n==0:\n",
    "        temp = temp['2017-06-13':'2017-06-18']\n",
    "        \n",
    "        traincandidate = temp\n",
    "        \n",
    "        data = temp.drop_duplicates(subset=['contentId'], keep = 'first').reset_index()\n",
    "\n",
    "        del data[\"index\"]\n",
    "\n",
    "        \n",
    "    if n==1:\n",
    "        \n",
    "        data = temp['2017-06-19']\n",
    "        \n",
    "        #data = temp.drop_duplicates(subset=['contentId'], keep = 'first').reset_index()\n",
    "\n",
    "        #del data[\"index\"]\n",
    "        \n",
    "        \n",
    "    \n",
    "    return traincandidate,data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traincandidate,trainaction = contextvectorfun(grouped_rich_impression,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02609583359918331"
      ]
     },
     "execution_count": 756,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(traincandidate[traincandidate[\"isClicked\"]==1])/len(traincandidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2524"
      ]
     },
     "execution_count": 757,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traincandidate.frontPageViewId.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_,testcadidate = contextvectorfun(grouped_rich_impression,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CCM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sat(impressions):\n",
    "    \n",
    "    up = impressions.groupby([\"contentId\"]).aggregate({\"satisfiedlist\":sum})\n",
    "    \n",
    "    down = impressions.groupby([\"contentId\"]).aggregate({\"isClicked\":sum})\n",
    "    \n",
    "    up[\"sat\"] = up.satisfiedlist.values/down.isClicked.values\n",
    "    \n",
    "    \n",
    "    result = up.fillna(0)\n",
    "    \n",
    "    result = result.sat.to_dict()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tua probability calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shrinkdataset = grouped_rich_impression[[\"date\",\"frontPageViewId\",\"contentPosition\",\"contentId\",\"satisfiedlist\",\"isClicked\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def tua_inf(newtua_impression):\n",
    "    \n",
    "    #newtua_impression = grouped_rich_impression[[\"frontPageViewId\",\"contentPosition\",\"contentId\",\"satisfiedlist\",\"isClicked\"]]\n",
    "    \n",
    "    #down = len(set(process_dataset.frontPageViewId.values))\n",
    "    \n",
    "    idx  = newtua_impression.groupby(['frontPageViewId'])[\"contentPosition\"].transform(max) == newtua_impression[\"contentPosition\"]\n",
    "\n",
    "    newtua_impression = newtua_impression[idx]\n",
    "    \n",
    "    count = Counter(newtua_impression.contentPosition.values)\n",
    "    \n",
    "    a = list(count.values())\n",
    "    \n",
    "    n = len(a)\n",
    "    \n",
    "    examination_inf = {}\n",
    "    \n",
    "    for i in range(len(a)):\n",
    "   \n",
    "        examination_inf[i+1] = sum(a[i:n])\n",
    "    \n",
    "    temp = list( examination_inf.values())\n",
    "    \n",
    "    tua_probability = {}\n",
    "    for i in range(1,62):\n",
    "         tua_probability[i] = 0.02\n",
    "    \n",
    "    \n",
    "    \n",
    "    tua_probability[1] = 1\n",
    "    \n",
    "    for i in range(len(a)):\n",
    "        if i == 0:\n",
    "            tua_probability[i+1] = 1\n",
    "        else:\n",
    "            tua_probability[i+1] = temp[i]/temp[i-1]\n",
    "\n",
    "\n",
    "    return  tua_probability\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = shrinkdataset[((shrinkdataset['satisfiedlist'] == 0) & (shrinkdataset['isClicked'] == 0))]\n",
    "\n",
    "tua_s0c0 = tua_inf(dataset) # = tua 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = shrinkdataset[((shrinkdataset['satisfiedlist'] == 0) & (shrinkdataset['isClicked'] == 1))]\n",
    "\n",
    "tua_s0c1 = tua_inf(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = shrinkdataset[((shrinkdataset['satisfiedlist'] == 1) & (shrinkdataset['isClicked'] == 1))]\n",
    "\n",
    "tua_s1c1 = tua_inf(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = shrinkdataset[((shrinkdataset['satisfiedlist'] == 1) & (shrinkdataset['isClicked'] == 0))]\n",
    "\n",
    "tua_s1c0 = tua_inf(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### satisficaiton probability of the train action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sat_prob_train = sat(train_data_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sat_prob_test = sat(test_data_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CTR of the train action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CTRperaction(grouped_rich_impression):\n",
    "\n",
    "    up = grouped_rich_impression.groupby([\"contentId\"]).aggregate({\"isClicked\":sum})\n",
    "    \n",
    "    down = grouped_rich_impression.groupby([\"contentId\"]).aggregate({\"isClicked\":len})\n",
    "    \n",
    "    CTR = up.isClicked.values/down.isClicked.values\n",
    "    \n",
    "    up[\"CTR\"] = CTR\n",
    "    \n",
    "    result = up.sort(columns=\"CTR\")\n",
    "    \n",
    "    result = result.CTR.to_dict()\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/XiHUANG/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:11: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n"
     ]
    }
   ],
   "source": [
    "CTR_TRAIN = CTRperaction(train_data_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bandit by myself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random as rand\n",
    "\n",
    "\n",
    "#sat_state = []\n",
    "#click_state = []\n",
    "\n",
    "#position = 1\n",
    "\n",
    "def rewardactionfun(Q,sat_prob,examination,epsilon):\n",
    "    \n",
    "    \n",
    "    if rand.random() > epsilon:\n",
    "        d = dict((k, v) for k, v in Q.items() if v == max(Q.values()))\n",
    "       \n",
    "        \n",
    "        action = rand.choice(list(d.keys()))\n",
    "    else:\n",
    "        action = rand.choice(list(Q.keys()))\n",
    "\n",
    "    reward = sat_prob[action]*examination\n",
    "    return action,reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "def selectcadidate(trainvalue, candidate):\n",
    "    S = defaultdict(float)\n",
    "    for item in list(candidate.keys()):\n",
    "    \n",
    "       S[item]= float(1 - spatial.distance.cosine(list(trainvalue), list(candidate[item])) )\n",
    "    \n",
    "    if len(S) == 0:\n",
    "        \n",
    "        result = random.choice(list(candidate.keys()))\n",
    "    else:\n",
    "    \n",
    "        result = max(S.items(), key=operator.itemgetter(1))[0]\n",
    "    \n",
    "   \n",
    "        \n",
    "    \n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stateidentify(satvalue,reward):\n",
    "   \n",
    "    if(satvalue >= parameter_threshold):\n",
    "        #sat_state.append(1)\n",
    "        sat_state = 1\n",
    "    else:\n",
    "\n",
    "        #sat_state.append(0)\n",
    "        sat_state = 0\n",
    "\n",
    "    if(reward >= parameter_threshold):\n",
    "        #click_state.append(1)\n",
    "        click_state = 1\n",
    "    else:\n",
    "        #click_state(0)\n",
    "        click_state = 0\n",
    "    return click_state,sat_state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def actionvalueupdate(alpha,action,reward,Q,count):\n",
    "    copy_Q = Q\n",
    "    old_Q = copy_Q[action]\n",
    "    Q[action] = (old_Q + (alpha*(reward-old_Q)))/count\n",
    "    Q = {k: Q[k] for k in Q if not isnan(Q[k])}\n",
    "    \n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def examinationfunc(position,pre_sat_state,pre_click_state):\n",
    "    \n",
    "    if pre_sat_state == 1 and pre_click_state == 1:\n",
    "        return tua_s1c1[position]\n",
    "    if pre_sat_state == 0 and pre_click_state == 1:\n",
    "        return tua_s0c1[position]\n",
    "    if pre_sat_state == 0 and pre_click_state == 0:\n",
    "        return tua_s0c0[position]\n",
    "    if pre_sat_state == 1 and pre_click_state == 0:\n",
    "        return tua_s1c0[position]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement the bandit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q = CTR_TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def candidateslection(impression):\n",
    "    result = impression.set_index(\"contentId\").contextvector.to_dict()\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cadidateisclick(impression):\n",
    "    result = impression.set_index(\"contentId\").isClicked.to_dict()\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traincontext = trainaction.set_index(\"contentId\").contextvector.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "904"
      ]
     },
     "execution_count": 1008,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(traincontext.values())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inputvalue(df):\n",
    "    tmp = df.groupby(\"frontPageViewId\").apply(lambda x:candidateslection(x))\n",
    "\n",
    "    tmp = tmp.to_frame(name=\"article\")\n",
    "\n",
    "    global_candidate = tmp[\"article\"].to_dict()\n",
    "    return global_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_candidate = inputvalue(testcadidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1011,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_train = inputvalue(traincandidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2524"
      ]
     },
     "execution_count": 1012,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(global_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1013,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = testcadidate.groupby(\"frontPageViewId\").apply(lambda x:cadidateisclick(x))\n",
    "\n",
    "tmp = tmp.to_frame(name=\"click\")\n",
    "\n",
    "test_click =  tmp[\"click\"].to_dict()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_candidate = inputvalue(testcadidate)\n",
    "test_candidate = global_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_candidate = global_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameter_threshold = 0.6\n",
    "parameter_alpha = 0.15\n",
    "epsilon = 0\n",
    "#countdic = defaultdict(int)\n",
    "new_frontpage = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CCM_BANDIT(sessioninput,Q,flag):\n",
    "    total_predictdataset = pd.DataFrame()\n",
    "    for item in list(sessioninput.keys()):\n",
    "        countdic = defaultdict(int)\n",
    "        position=1\n",
    "        #print(position)\n",
    "        candidate = sessioninput[item]\n",
    "        while(len(candidate) != 0):\n",
    "\n",
    "            if position == 1:\n",
    "                Q_pre = Q\n",
    "                #print(position)\n",
    "                #Q_0 = CTR_TRAIN\n",
    "                action,reward = rewardactionfun(Q_pre,sat_prob_train,1,epsilon)\n",
    "                countdic[action]+=1\n",
    "                choosefromcadidate = selectcadidate(traincontext[action], candidate)\n",
    "                click_state,sat_state = stateidentify(sat_prob_train[action],reward)\n",
    "                #print(test_click[item][choosefromcadidate])\n",
    "                if flag == 0:\n",
    "                    new_frontpage= pd.DataFrame({\"position\":[position],\"frontpageid\":item ,\"contentid\":choosefromcadidate,\n",
    "                                             \"probablectr\":[reward],\n",
    "                                            })\n",
    "                if flag == 1:\n",
    "                    new_frontpage= pd.DataFrame({\"position\":[position],\"frontpageid\":item ,\"contentid\":choosefromcadidate,\n",
    "                                             \"probablectr\":[reward],\n",
    "                                            \"isclickreal\": [test_click[item][choosefromcadidate]]})\n",
    "                Q = actionvalueupdate(parameter_alpha,action,reward,Q_pre,countdic[action])\n",
    "                del candidate[choosefromcadidate]\n",
    "                position+=1\n",
    "            else:\n",
    "\n",
    "\n",
    "                Q_pre = Q\n",
    "\n",
    "                examination = examinationfunc(position,sat_state,click_state)\n",
    "\n",
    "                if examination == 0:\n",
    "                    break\n",
    "                else:\n",
    "\n",
    "                    action,reward = rewardactionfun(Q_pre,sat_prob_train,examination,epsilon)\n",
    "                    choosefromcadidate = selectcadidate(traincontext[action], candidate)\n",
    "                    #print(action)\n",
    "                    countdic[action] += 1\n",
    "                    click_state,sat_state = stateidentify(sat_prob_train[action],reward)\n",
    "                    if flag == 0:\n",
    "                        new_frontpage = new_frontpage.append(pd.DataFrame({\"position\":[position],\"frontpageid\":item, \"contentid\":choosefromcadidate,\n",
    "                                                                       \"probablectr\":[reward],\n",
    "                                                                       \n",
    "                                    }))\n",
    "                    if flag == 1:\n",
    "                        new_frontpage = new_frontpage.append(pd.DataFrame({\"position\":[position],\"frontpageid\":item, \"contentid\":choosefromcadidate,\n",
    "                                                                       \"probablectr\":[reward],\n",
    "                                                                       \"isclickreal\": [test_click[item][choosefromcadidate]]\n",
    "                                    }))\n",
    "                    Q = actionvalueupdate(parameter_alpha,action,reward,Q_pre,countdic[action])\n",
    "                    del candidate[choosefromcadidate]\n",
    "                    position+=1\n",
    "        total_predictdataset = total_predictdataset.append(new_frontpage)\n",
    "    return total_predictdataset, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,Q = CCM_BANDIT(train_candidate,Q,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total_predictdataset,_Q = CCM_BANDIT(test_candidate,Q,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluation -- map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def truemap(df):\n",
    "    maplist = []\n",
    "    maxposition = max(list(df.contentPosition.values))\n",
    "    #print(maxposition)\n",
    "    clicklist = [0]*maxposition\n",
    "    for item in df[df[\"isClicked\"] == 1].contentPosition.values:\n",
    "        clicklist[item-1] = 1\n",
    "    for i in range(maxposition):\n",
    "        #print(i)\n",
    "        n = i+1\n",
    "        maplist.append(sum(clicklist[:n])/n)\n",
    "    \n",
    "    result = sum(maplist)/len(maplist)\n",
    "    return result\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictmap(df):\n",
    "    maplist = df.isclickreal.cumsum().values / df.position.values\n",
    "    result = maplist.mean()\n",
    "    return result\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ap_true = testcadidate.groupby(\"frontPageViewId\").apply(lambda x:truemap(x))\n",
    "\n",
    "ap_true = ap_true.to_frame(name = \"ap\").reset_index()\n",
    "\n",
    "ap_true = ap_true[ap_true[\"ap\"] != 0.0]\n",
    "\n",
    "ap_true[\"represent_frontpage\"] = list(ap_true.index.values)\n",
    "\n",
    "ap_predict = total_predictdataset.groupby(\"frontpageid\").apply(lambda x:predictmap(x))\n",
    "\n",
    "ap_predict = ap_predict.to_frame(name=\"ap\").reset_index()\n",
    "\n",
    "ap_predict = ap_predict[ap_predict[\"ap\"] != 0.0]\n",
    "\n",
    "ap_predict[\"represent_frontpage\"] = list(ap_predict.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map true %s 0.119271991151\n",
      "map predict %s 0.165651911444\n",
      "improvement %s 0.388858438981\n"
     ]
    }
   ],
   "source": [
    "map_true = ap_true.ap.values.sum()/len(ap_true)\n",
    "\n",
    "map_predict = ap_predict.ap.values.sum()/len(ap_predict)\n",
    "\n",
    "improvement = (map_predict - map_true)/map_true\n",
    "\n",
    "print(\"map true %s\", map_true)\n",
    "\n",
    "print(\"map predict %s\", map_predict)\n",
    "\n",
    "print(\"improvement %s\", improvement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluation--myself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newfrontpage = total_predictdataset.groupby([\"position\"])[\"contentid\"].last()\n",
    "\n",
    "new_frontpage = newfrontpage.to_frame().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generalexam(grouped_rich_impression):\n",
    "    #n = len(a)\n",
    "    idx  = grouped_rich_impression.groupby(['frontPageViewId'])[\"contentPosition\"].transform(max) == grouped_rich_impression[\"contentPosition\"]\n",
    "\n",
    "    temp = grouped_rich_impression[idx]\n",
    "\n",
    "    result = {}\n",
    "\n",
    "    count = Counter(temp.contentPosition.values)\n",
    "\n",
    "    list1 = [i+1 for i in range(61)]\n",
    "    #nn = len(a)\n",
    "\n",
    "    for item in list1:\n",
    "        if item not in list(count.keys()):\n",
    "             count[item] = 0\n",
    "\n",
    "    a = list(count.values())  \n",
    "\n",
    "    up = len(set(grouped_rich_impression.frontPageViewId.values))\n",
    "\n",
    "    for i in range(len(list1)):\n",
    "\n",
    "        result[i+1] = (sum(a[i:len(list1)])/up+0.001)\n",
    "        \n",
    "    return result\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "general_exam = generalexam(grouped_rich_impression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluationmy(testcadidate,new_frontpage,general_exam):\n",
    "    oldfrontpage = testcadidate.groupby([\"contentPosition\"])[\"contentId\"].last()\n",
    "\n",
    "    oldfrontpage = oldfrontpage.to_frame().reset_index()\n",
    "    \n",
    "    \n",
    "    position_content = oldfrontpage.set_index(\"contentId\").contentPosition.to_dict()\n",
    "    \n",
    "    position_content_predict = new_frontpage.set_index(\"contentid\").position.to_dict()\n",
    "    \n",
    "    true_crt = []\n",
    "    for item in position_content.keys():\n",
    "\n",
    "        true_crt.append(sat_prob_test[item]*general_exam[position_content[item]])\n",
    "        \n",
    "    pretect_rocrt = []\n",
    "    ave_true_crt = sum(true_crt)/len(true_crt)\n",
    "    \n",
    "    for item in position_content_predict.keys():\n",
    "\n",
    "        pretect_rocrt.append(sat_prob_test[item]*general_exam[position_content_predict[item]])\n",
    "    \n",
    "    ave_pre_crt = sum(pretect_rocrt)/len(pretect_rocrt)\n",
    "\n",
    "    improvement1 = (ave_pre_crt-ave_true_crt)/ave_true_crt\n",
    "\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    return improvement1\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7035"
      ]
     },
     "execution_count": 1001,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testcadidate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1028,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0370371375817649"
      ]
     },
     "execution_count": 1028,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluationmy(testcadidate,new_frontpage,general_exam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### epsilon greedy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rewardactionfungreedy(Q,sat_prob,epsilon):\n",
    "    \n",
    "    \n",
    "    if rand.random() > epsilon:\n",
    "        d = dict((k, v) for k, v in Q.items() if v == max(Q.values()))\n",
    "       \n",
    "        \n",
    "        action = rand.choice(list(d.keys()))\n",
    "    else:\n",
    "        action = rand.choice(list(Q.keys()))\n",
    "\n",
    "    reward = sat_prob[action]\n",
    "    return action,reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def actionvalueepsilonupdate(alpha,action,reward,Q):\n",
    "    copy_Q = Q\n",
    "    old_Q = copy_Q[action]\n",
    "    Q[action] = old_Q + (alpha*(reward-old_Q))\n",
    "    Q = {k: Q[k] for k in Q if not isnan(Q[k])}\n",
    "    \n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainaction[\"initial\"] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content_Q = trainaction.set_index('contentId')['initial'].to_dict()\n",
    "\n",
    "content_vector = trainaction.set_index('contentId')['contextvector'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q = content_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "time = 1\n",
    "    \n",
    "while(time<=10000):\n",
    "\n",
    "        \n",
    "            Q_pre = Q\n",
    "            #print(position)\n",
    "            #Q_0 = CTR_TRAIN\n",
    "            action,reward = rewardactionfungreedy(Q_pre,sat_prob_train,epsilon=0.01)\n",
    "            Q = actionvalueepsilonupdate(parameter_alpha,action,reward,Q_pre)\n",
    "            \n",
    "        \n",
    "            time+=1\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Q = sorted(Q.items(), key=lambda kv: kv[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import uniform, random, choice, sample\n",
    "def selectcadidate_e(trainvalue, candidate):\n",
    "            \n",
    "        \n",
    "    \n",
    "    \n",
    "                S = defaultdict(float)\n",
    "                resultdic = defaultdict(float)\n",
    "                for item in list(candidate.keys()):\n",
    "                            #print(item)\n",
    "\n",
    "\n",
    "                        S[item]= float(1 - spatial.distance.cosine(list(trainvalue), list(candidate[item]))) \n",
    "\n",
    "\n",
    "\n",
    "                if len(S) == 0:\n",
    "                    result = rand.choice(list(candidate.keys()))\n",
    "\n",
    "                else:\n",
    "                    result = max(S.items(), key=operator.itemgetter(1))[0]\n",
    "                \n",
    "                return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = testcadidate.drop_duplicates(subset=['contentId'], keep = 'first').reset_index()\n",
    "\n",
    "test_vector = test_data.set_index('contentId')['contextvector'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalbandit(inputvalue,item):\n",
    "    result_frontpage = pd.DataFrame()\n",
    "\n",
    "    candidate = inputvalue\n",
    "\n",
    "    for i in range(len(Q)):\n",
    "            if len(candidate) == 0:\n",
    "                break\n",
    "            else:\n",
    "\n",
    "                trainitem = Q[i][0]\n",
    "                article = selectcadidate_e(content_vector[trainitem], candidate)\n",
    "                        #print(article)\n",
    "                result_frontpage = result_frontpage.append(pd.DataFrame({\"frontpageid\":item,\"contentid\": article,\"value\":Q[i][1],\"position\":[i+1],\"isclickreal\": [test_click[item][article]]}))\n",
    "\n",
    "                del candidate[article] \n",
    "        #total_predictdataset = total_predictdataset.append(result_frontpage)\n",
    "    return result_frontpage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "global_candidate = inputvalue(testcadidate)\n",
    "test_candidate = global_candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 971,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalfront = pd.DataFrame()\n",
    "for item in list(test_candidate.keys()):\n",
    "        \n",
    "        #print(position)\n",
    "        candidate = test_candidate[item]\n",
    "        totalfront=totalfront.append(generalbandit(candidate,item))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_frontpage = result_frontpage[:61]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 972,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluationlb(testcadidate,new_frontpage,general_exam):\n",
    "    contentlist = list(testcadidate.contentId.values)\n",
    "    \n",
    "    idx = new_frontpage.contentid.isin(contentlist)\n",
    "    \n",
    "    new_frontpage = new_frontpage[idx]\n",
    "    \n",
    "    \n",
    "    oldfrontpage = testcadidate.groupby([\"contentPosition\"])[\"contentId\"].last()\n",
    "\n",
    "    oldfrontpage = oldfrontpage.to_frame().reset_index()\n",
    "    \n",
    "    position_content = oldfrontpage.set_index(\"contentId\").contentPosition.to_dict()\n",
    "    \n",
    "    position_content_predict = new_frontpage.set_index(\"contentid\").position.to_dict()\n",
    "    \n",
    "    true_crt = []\n",
    "    for item in position_content.keys():\n",
    "\n",
    "        true_crt.append(sat_prob_test[item]*general_exam[position_content[item]])\n",
    "    ave_true_crt = sum(true_crt)/len(true_crt)\n",
    "        \n",
    "    pretect_rocrt = []\n",
    "    \n",
    "    for item in position_content_predict.keys():\n",
    "\n",
    "        pretect_rocrt.append(sat_prob_test[item]*general_exam[position_content_predict[item]])\n",
    "    \n",
    "    ave_pre_crt = sum(pretect_rocrt)/len(pretect_rocrt)\n",
    "\n",
    "    improvement1 = (ave_pre_crt-ave_true_crt)/ave_true_crt\n",
    "\n",
    "   \n",
    "    \n",
    "    #improvement2 = (ave_predict_ctr-ave_true_crt)/ave_true_crt\n",
    "    \n",
    "    return improvement1\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.467700472094867"
      ]
     },
     "execution_count": 999,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluationmy(testcadidate,totalfront,general_exam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.467700472094867"
      ]
     },
     "execution_count": 973,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluationlb(testcadidate,totalfront,general_exam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### map epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map true %s 0.119271991151\n",
      "map predict %s 0.173521058299\n",
      "improvement %s 0.454834924987\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "ap_predict =totalfront.groupby(\"frontpageid\").apply(lambda x:predictmap(x))\n",
    "\n",
    "ap_predict = ap_predict.to_frame(name=\"ap\").reset_index()\n",
    "\n",
    "ap_predict = ap_predict[ap_predict[\"ap\"] != 0.0]\n",
    "\n",
    "ap_predict[\"represent_frontpage\"] = list(ap_predict.index.values)\n",
    "\n",
    "map_predict = ap_predict.ap.values.sum()/len(ap_predict)\n",
    "\n",
    "improvement = (map_predict - map_true)/map_true\n",
    "\n",
    "print(\"map true %s\", map_true)\n",
    "\n",
    "print(\"map predict %s\", map_predict)\n",
    "\n",
    "print(\"improvement %s\", improvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
